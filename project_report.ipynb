{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec11ef80",
   "metadata": {},
   "source": [
    "# Project Report Vincent Sebastian  Financial Assistant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b5cee",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Executive Summary\n",
    "\n",
    "This capstone project presents an integrated AI-powered financial assistant application that combines conversational AI capabilities with document analysis features. The application leverages Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) to provide intelligent financial insights and document Q&A capabilities through an intuitive Streamlit interface.\n",
    "\n",
    "**Key Features:**\n",
    "- ðŸ’¬ **Financial Chatbot**: Intelligent conversational agent for financial queries\n",
    "- ðŸ“„ **Document Assistant**: PDF analysis with summarization and Q&A capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bc469",
   "metadata": {},
   "source": [
    "## 1. Problem Statement & Use Case\n",
    "\n",
    "My project is about having a reliable financial assistant that will help you save much time just to analyze one company, so when AI start to analyze you can rest or do something else, and not only one, it's more than one company so you will have a bigger picture of the sectors and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cf24b",
   "metadata": {},
   "source": [
    "## 2. Objective of the Application\n",
    "The Primary objective is to having a conversational with reliable financial assitant not only getting information about the company but can understand the provided financial file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91f535",
   "metadata": {},
   "source": [
    "## 3. LLM Usage Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f6dfa",
   "metadata": {},
   "source": [
    "For my project i'm using ChatGroq with `llama-3.3-70b-versatile` model dan low temperature, here my integration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58640b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/finai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
    "\n",
    "SECTORS_API_KEY = st.secrets[\"SECTORS_API_KEY\"]\n",
    "GROQ_API_KEY = st.secrets[\"GROQ_API_KEY\"]\n",
    "\n",
    "\n",
    "def retrieve_from_endpoint(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    A robust, reusable helper function to perform GET requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\"Authorization\": SECTORS_API_KEY}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        return data\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        return {\n",
    "            \"error\": f\"HTTPError {err.response.status_code} - {err.response.reason}\",\n",
    "            \"url\": url,\n",
    "            \"detail\": err.response.text\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Unexpected error: {type(e).__name__} - {str(e)}\",\n",
    "            \"url\": url\n",
    "        }\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_company_overview(stock: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get company overview\n",
    "    \n",
    "    @param stock: The stock symbol of the company\n",
    "    @return: The company overview\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/company/report/{stock}/?sections=overview\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_company_revenue_cost_segments(stock : str) -> dict :\n",
    "    \"\"\"\n",
    "    Return revenue and cost segments of a given stock.\n",
    "\n",
    "    @param stock: The stock symbol of the company\n",
    "    @return: The company revenue and cost segments\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/company/get-segments/{stock}/\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "@tool\n",
    "def get_top_companies_by_tx_volume(start_date: str, end_date: str, top_n: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Get top companies by transaction volume\n",
    "\n",
    "    @param start_date: The start date in YYYY-MM-DD format\n",
    "    @param end_date: The end date in YYYY-MM-DD format\n",
    "    @param top_n: Number of stocks to show\n",
    "    @return: A list of most traded IDX stocks based on transaction volume for a certain interval\n",
    "    \"\"\"\n",
    "    url = f\"https://api.sectors.app/v1/most-traded/?start={start_date}&end={end_date}&n_stock={top_n}\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "@tool\n",
    "def get_daily_tx(stock: str, start_date: str, end_date: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get daily transaction for a stock\n",
    "\n",
    "    @param stock: The stock 4 letter symbol of the company\n",
    "    @param start_date: The start date in YYYY-MM-DD format\n",
    "    @param end_date: The end date in YYYY-MM-DD format\n",
    "    @return: Daily transaction data of a given ticker for a certain interval\n",
    "    \"\"\"\n",
    "    url = f\"https://api.sectors.app/v1/daily/{stock}/?start={start_date}&end={end_date}\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_top_companies_ranked(dimension: str, top_n: int, year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Return a list of top companies (symbol) based on certain dimension \n",
    "    (dividend yield, total dividend, revenue, earnings, market cap,...)\n",
    "\n",
    "    @param dimension: The dimension to rank the companies by, one of: \n",
    "    \"dividend_yield\", \"total_dividend\", \"revenue\", \"earnings\", \"market_cap\", ...\n",
    "\n",
    "    @param top_n: Number of stocks to show\n",
    "    @param year: Year of ranking, always show the most recent full calendar year that has ended\n",
    "    @return: A list of top tickers in a given year based on certain classification\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/companies/top/?classifications={dimension}&n_stock={top_n}&year={year}\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "@tool\n",
    "def get_top_companies_by_growth(dimension : str, sub_sectors : str) -> dict :\n",
    "    \"\"\"\n",
    "    Return a list of top companies (symbol) based on certain dimension \n",
    "    (top_earnings_growth_gainers, top_earnings_growth_losers, top_revenue_growth_gainers, top_revenue_growth_losers,...)\n",
    "\n",
    "    @param dimension : The dimension to rank the companies by, one of: \n",
    "    top_earnings_growth_gainers, top_earnings_growth_losers, top_revenue_growth_gainers, top_revenue_growth_losers.\n",
    "    @param sub_sectors : use get_company_overview tools to get the subsectors of the company, if not provided just leave it blank\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/companies/top-growth/?classifications={dimension}&n_stock=5&sub_sector={sub_sectors}\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "@tool\n",
    "def get_top_companies_by_mover(dimension : str, period : str, sub_sectors : str) -> dict :\n",
    "    \"\"\"\n",
    "    Return a list of top companies (symbol) based on certain dimension on certain period\n",
    "    (top_gainers, top_losers,...)\n",
    "\n",
    "    @param dimension : The dimension to rank the companies by, one of: \n",
    "    (top_gainers, top_losers)\n",
    "    @param period : The certain period, one of:\n",
    "    (1d, 7d, 14d, 30d, 365d)\n",
    "    @param sub_sectors : use get_company_overview tools to get the subsectors of the company, if not provided just leave it blank\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.sectors.app/v1/companies/top-changes/?classifications={dimension}&n_stock=5&periods={period}&sub_sector={sub_sectors}\"\n",
    "\n",
    "    return retrieve_from_endpoint(url)\n",
    "\n",
    "def get_finance_agent():\n",
    "\n",
    "    # Defined Tools\n",
    "    tools = [\n",
    "        get_company_overview,\n",
    "        get_top_companies_by_tx_volume,\n",
    "        get_daily_tx,\n",
    "        get_top_companies_ranked,\n",
    "        get_top_companies_by_growth,\n",
    "        get_top_companies_by_mover,\n",
    "        get_company_revenue_cost_segments\n",
    "    ]\n",
    "\n",
    "    # Create the Prompt Template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"\"\"\n",
    "                Answer the following queries, being as factual and analytical as you can. \n",
    "                If you need the start and end dates but they are not explicitly provided, \n",
    "                infer from the query. Whenever you return a list of names, return also the \n",
    "                corresponding values for each name. If the volume was about a single day, \n",
    "                the start and end parameter should be the same. Note that the endpoint for \n",
    "                performance since IPO has only one required parameter, which is the stock. \n",
    "                Today's date is {datetime.today().strftime(\"%Y-%m-%d\")}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Initializing the LLM\n",
    "    llm = ChatGroq(\n",
    "        temperature=0,\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        groq_api_key=GROQ_API_KEY,\n",
    "    )\n",
    "\n",
    "    # Create the Agent and AgentExecutor\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    # Add Memory to the AgentExecutor\n",
    "    def get_session_history(session_id: str):\n",
    "\n",
    "        return StreamlitChatMessageHistory(key=session_id)\n",
    "    \n",
    "    agent_with_memory = RunnableWithMessageHistory(\n",
    "        agent_executor,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "    )\n",
    "\n",
    "    return agent_with_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877fc0f4",
   "metadata": {},
   "source": [
    "For extra i'm using RAG for understanding the uploaded file, \n",
    "HuggingFace for embedding with `sentence-transformers/all-mpnet-base-v2` model, here my implementation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ec2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "llm = ChatGroq(model=MODEL, temperature=0.0)\n",
    "\n",
    "def create_pdf_agent(file) :\n",
    "\n",
    "        # Simpan PDF ke file sementara\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file :\n",
    "            tmp_file.write(file.read())\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        loader = PyPDFLoader(tmp_path)\n",
    "        docs = loader.load()\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,  \n",
    "            chunk_overlap=200   \n",
    "        )\n",
    "\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "        embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "        vector_store_pdf = InMemoryVectorStore(embedding)\n",
    "        _ = vector_store_pdf.add_documents(documents=all_splits)\n",
    "\n",
    "        tools = create_retriever_tool(vector_store_pdf.as_retriever(search_kwargs={'k': 5}),\n",
    "                                        name = \"pdf_document_retriever\",\n",
    "                                        description= \"Retrieve PDF as context to accurately and concisely answer the user's question\")\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\n",
    "                        \"system\",\n",
    "                        '''\n",
    "                        You are a helpful and detail-oriented assistant. \n",
    "                        You are provided with a tool to retrieve a PDF document from a vector store. \n",
    "                        Use the context to accurately and concisely answer the user's question. \n",
    "\n",
    "                        You need to follow these rules:\n",
    "                        - Only use data from tools provided. Never guess or use outside data.  \n",
    "                        - If data is not available, say so clearly and do not make it up. Suggest alternative sources if possible.  \n",
    "                        - Add follow-up questions to help users dive deeper  \n",
    "                        '''\n",
    "                    ),\n",
    "                    (\n",
    "                        \"human\", \"{input}\"\n",
    "                    ),\n",
    "                    MessagesPlaceholder(\"agent_scratchpad\")\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Create the Agent and AgentExecutor\n",
    "        agent = create_tool_calling_agent(llm, [tools], prompt)\n",
    "        \n",
    "        agent_executor_pdf = AgentExecutor(agent=agent, tools=[tools], verbose=True)\n",
    "\n",
    "        return agent_executor_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de89ed8",
   "metadata": {},
   "source": [
    "## 4. Data Flow & Processing Steps\n",
    "\n",
    "Data Flow : User input (text/upload only pdf file) -> LLM Processing (get related data from Sectors API / Understanding Document) -> Generate Response -> Display Response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f429df",
   "metadata": {},
   "source": [
    "## 5. UI/UX Considerations\n",
    "\n",
    "I'm using a simple and clean UI to making a easy friendly web and not too much noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7d3db",
   "metadata": {},
   "source": [
    "## 6. Deployment Notes\n",
    "\n",
    "This project will deploy Streamlit Cloud using Python 3.11 and the secret keys will stored in Streamlit secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52840a27",
   "metadata": {},
   "source": [
    "## 7. Reflection & Next Steps\n",
    "\n",
    "While i'm making this project i wanna try to develop with a really real-time based data to improve accuracy, but i'll cost a lot for me, and i think we can combine with others API to compare the data(s), not only via sectors while it can take a longer time in user, but with a little longer wait for better data i think it's fair enough and improve in user system, so it can CRUD for user and integrate for predictive analysis with disclaimer ofc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finai",
   "language": "python",
   "name": "finai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
